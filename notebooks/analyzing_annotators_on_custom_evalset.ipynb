{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for analysing annotators on custom datasets\n",
    "\n",
    "By default annotators (also referred to as \"annotators\") are tested on the standard AlpacaEval cross annotated dataset, with 650 different text pairs. This notebook illustrates the use of the `analyze_evaluators` function with custom datasets (not these 650 pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: the dataset needs generator column, as this is used for correlation of winrates (output_2 is generated by \"generator\" model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Default use-case (for testing)\n",
    "\n",
    "from alpaca_eval import main, constants\n",
    "\n",
    "# Default annotator leaderboard on standard AlpacaEval cross-annotated dataset\n",
    "evaluator_leaderboard, all_crossannotations = main.analyze_evaluators(\n",
    "    # annotators_config=None,\n",
    "    annotators_config=constants.DEFAULT_ANNOTATOR_CONFIG,\n",
    "    is_return_instead_of_print=True,\n",
    "    max_instances=2,\n",
    "    is_single_annotator=True,\n",
    "    precomputed_leaderboard=\"tmp_leaderboard2.csv\",\n",
    ")\n",
    "evaluator_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom leaderboard on custom dataset\n",
    "\n",
    "# note that this assumes that the OpenAI API key is set in client_configs\n",
    "from alpaca_eval import main, constants\n",
    "\n",
    "human_crossannotations_path = \"test_custom_crossannotations.json\"\n",
    "leaderboard_path = \"tmp_leaderboard.csv\"\n",
    "\n",
    "# Default annotator leaderboard on standard AlpacaEval cross-annotated dataset\n",
    "evaluator_leaderboard, all_crossannotations = main.analyze_evaluators(\n",
    "    annotators_config= constants.DEFAULT_ANNOTATOR_CONFIG,\n",
    "    is_return_instead_of_print=True,\n",
    "    precomputed_leaderboard=leaderboard_path,\n",
    "    is_single_annotator=True,\n",
    "    analyzer_kwargs={\n",
    "        \"gold_crossannotations\": human_crossannotations_path,\n",
    "        \"gold_annotations\": None,\n",
    "    }\n",
    ")\n",
    "evaluator_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
